{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T0n-k4/Ugliest-Nightmare-Prettiest-Dream/blob/main/Lab_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "PQsLStfxfRrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "X2noEVRFmHTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "from imageio import *\n",
        "import torch\n",
        "from skimage.transform import resize\n",
        "from mpl_toolkits.axes_grid1.axes_rgb import make_rgb_axes, RGBAxes\n",
        "from torchvision.models import *\n",
        "from torchvision.datasets import MNIST,KMNIST,FashionMNIST\n",
        "from skimage.util import montage"
      ],
      "metadata": {
        "id": "aGu2hYn5VgKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: `numpy` for numerical computations, `matplotlib.pyplot` for plotting graphs, `urllib.request` for accessing URLs, `PIL.Image` for working with images, `imageio` for reading and writing various image formats, `torch` for machine learning, `skimage.transform.resize` for resizing images, `mpl_toolkits.axes_grid1.axes_rgb.make_rgb_axes` and `RGBAxes` for creating RGB axes, `torchvision.models` for pre-trained computer vision models, `torchvision.datasets` for common datasets like MNIST and FashionMNIST, and `skimage.util.montage` for creating montages from images."
      ],
      "metadata": {
        "id": "aY6tVpiT2WXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb as wb"
      ],
      "metadata": {
        "id": "O1xRGxv7AfoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: Installed the wandb library using pip and imported it as wb. wandb is used for experiment tracking and visualization in machine learning projects, allowing you to log training runs, track hyperparameters, and visualize model performance."
      ],
      "metadata": {
        "id": "tQiDaOkK3GB4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDIXy7Gu3Il1"
      },
      "source": [
        "def plot(x):\n",
        "    if type(x) == torch.Tensor :\n",
        "        x = x.cpu().detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(x, cmap = 'gray')\n",
        "    ax.axis('off')\n",
        "    fig.set_size_inches(5, 5)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: This Python function, `plot`, takes an input `x` and plots it as an image. If `x` is a `torch.Tensor`, it converts it to a NumPy array first. It then creates a new figure using `plt.subplots()`, displays the image using `ax.imshow()`, sets the axis off with `ax.axis('off')`, and sets the figure size to 5x5 inches. Finally, it shows the plot using `plt.show()`. The image is displayed in grayscale (`cmap='gray'`)."
      ],
      "metadata": {
        "id": "YZIoRlQZ3_Gi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDeM6b3J3HCm"
      },
      "source": [
        "def plot(x):\n",
        "    if type(x) == torch.Tensor :\n",
        "        x = x.cpu().detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(x, cmap = 'gray')\n",
        "    ax.axis('off')\n",
        "    fig.set_size_inches(5, 5)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DQxxGNl1E1o"
      },
      "source": [
        "def plot(x):\n",
        "    if type(x) == torch.Tensor :\n",
        "        x = x.cpu().detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(x, cmap = 'gray')\n",
        "    ax.axis('off')\n",
        "    fig.set_size_inches(5, 5)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLcWTt76COK2"
      },
      "source": [
        "def montage_plot(x):\n",
        "    x = np.pad(x, pad_width=((0, 0), (1, 1), (1, 1)), mode='constant', constant_values=0)\n",
        "    plot(montage(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: This function, `montage_plot`, takes an input `x`, pads it with zeros, creates a montage from the padded `x` using `montage`, and then plots the montage using the `plot` function defined earlier. The `montage` function creates a composite image from a collection of images, which can be useful for visualizing multiple images at once."
      ],
      "metadata": {
        "id": "9wr6h3C44Tl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = 1000\n",
        "\n",
        "def get_batch(mode):\n",
        "    if mode == \"train\":\n",
        "        r = np.random.randint(X.shape[0]-b)\n",
        "        x = X[r:r+b,:]\n",
        "        y = Y[r:r+b]\n",
        "    elif mode == \"test\":\n",
        "        r = np.random.randint(X_test.shape[0]-b)\n",
        "        x = X_test[r:r+b,:]\n",
        "        y = Y_test[r:r+b]\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "NZaGcRW6Igar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `get_batch` function is designed to retrieve a batch of data and labels for either training or testing purposes. When called with `\"train\"`, it selects a random batch of size `b` from the training data `X` and labels `Y`. When called with `\"test\"`, it selects a random batch of size `b` from the test data `X_test` and labels `Y_test`. The function then returns the batch of data `x` and the corresponding labels `y`."
      ],
      "metadata": {
        "id": "-voUgosQ4h83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## MNIST\n",
        "    "
      ],
      "metadata": {
        "id": "gkw9kmV4NyRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "Dc8TF76WPY1e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm7ZMYrVEdMX"
      },
      "source": [
        "# #MNIST\n",
        "train_set = MNIST('./data', train=True, download=True)\n",
        "test_set  = MNIST('./data', train=False, download=True)\n",
        "\n",
        "#KMNIST\n",
        "# train_set = KMNIST('./data', train=True, download=True)\n",
        "# test_set =  KMNIST('./data', train=False, download=True)\n",
        "\n",
        "# Fashion MNIST\n",
        "# train_set = FashionMNIST('./data', train=True, download=True)\n",
        "# test_set =  FashionMNIST('./data', train=False, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: These lines of code demonstrate how to load different datasets (MNIST, KMNIST, Fashion MNIST) using the torchvision library's dataset classes. These datasets are commonly used for training and testing machine learning models, particularly in image classification tasks. The datasets are downloaded and stored in the './data' directory."
      ],
      "metadata": {
        "id": "_3MzTMi18Dle"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ols0HivADS6a"
      },
      "source": [
        "X = train_set.data.numpy()\n",
        "X_test = test_set.data.numpy()\n",
        "Y = train_set.targets.numpy()\n",
        "Y_test = test_set.targets.numpy()\n",
        "\n",
        "X = X[:,None,:,:]/255\n",
        "X_test = X_test[:,None,:,:]/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The code converts the image data and labels from the MNIST dataset (`train_set` and `test_set`) into NumPy arrays. The images are reshaped to have a single channel and normalized to the range [0, 1]. The arrays `X` and `X_test` contain the image data, while `Y` and `Y_test` contain the corresponding labels, preparing the data for machine learning model training and testing."
      ],
      "metadata": {
        "id": "G3Am2_Hz8O5s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfAjr0UBjgfs"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y[50000]"
      ],
      "metadata": {
        "id": "PZ0TWqL3zjGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye809_jCAAxr"
      },
      "source": [
        "plot(X[50000,0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evX7gb0YBzpe"
      },
      "source": [
        "Y[100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "ZvRm1DjXzI91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ExpQONSaC_"
      },
      "source": [
        "X[0:25,0,:,:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHoMXjA6pWoa"
      },
      "source": [
        "montage_plot(X[125:150,0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: This line of code uses the `montage_plot` function to display a montage of a subset of images from the `X` array. Specifically, it selects rows 125 to 149 (inclusive) from the first channel (index 0) of `X`, which contains the preprocessed image data. The `montage_plot` function pads the images with zeros and then creates and displays a montage of these images."
      ],
      "metadata": {
        "id": "YyBA8WW18hUh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQPM_KQpD7Qd"
      },
      "source": [
        "X.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFqBciL5EPgM"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eAq9FpWES_1"
      },
      "source": [
        "X.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjqCYVv7EX1d"
      },
      "source": [
        "X_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GPU(data):\n",
        "    return torch.tensor(data, requires_grad=True, dtype=torch.float, device=torch.device('cuda'))\n",
        "\n",
        "def GPU_data(data):\n",
        "    return torch.tensor(data, requires_grad=False, dtype=torch.float, device=torch.device('cuda'))"
      ],
      "metadata": {
        "id": "PyV8c4cyPAWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `GPU` function converts input data into a PyTorch tensor that requires gradient computation and is located on the GPU. It sets the tensor's data type to float. The `GPU_data` function is similar but does not require gradient computation, making it suitable for data that does not need gradients, such as input data for inference or validation."
      ],
      "metadata": {
        "id": "cfRz2pio8pHt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBt4rsdIefV_"
      },
      "source": [
        "X = GPU_data(X)\n",
        "Y = GPU_data(Y)\n",
        "X_test = GPU_data(X_test)\n",
        "Y_test = GPU_data(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: These lines of code convert the NumPy arrays `X`, `Y`, `X_test`, and `Y_test` to PyTorch tensors located on the GPU, using the `GPU_data` function. This conversion is useful for utilizing GPU acceleration when training or running inference on machine learning models implemented with PyTorch."
      ],
      "metadata": {
        "id": "xmaCST0c81aS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.reshape(X.shape[0],784)\n",
        "X_test = X_test.reshape(X_test.shape[0],784)"
      ],
      "metadata": {
        "id": "qd6QY2wJ3DPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: These lines of code reshape the `X` and `X_test` arrays, which contain the image data, from their original shape (which likely represents images as 2D arrays) to a flattened shape where each image is represented as a 1D array of length 784 (28x28). This reshaping is often necessary when preparing image data to be fed into machine learning models that expect flattened input."
      ],
      "metadata": {
        "id": "ThT8Cou99OOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "MKUw3_YO39T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Classifier\n"
      ],
      "metadata": {
        "id": "aqdMV6v-2o3h"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqMKS4LqeBzy"
      },
      "source": [
        "x,y = get_batch('train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: This line of code calls the `get_batch` function with the argument `'train'`, which indicates that it should retrieve a batch of training data. It then unpacks the returned values into variables `x` and `y`, which represent the batch of input data and corresponding labels, respectively. This is a common pattern in machine learning where data is processed in batches during training."
      ],
      "metadata": {
        "id": "gNoAOnARGylV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvewlRZCeB20"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfywj66KFh8Y"
      },
      "source": [
        "plot(x[0].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsAhw-64HNJX"
      },
      "source": [
        "plot(x[1].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfIkv97VHRaH"
      },
      "source": [
        "plot(x[2].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTYYsbmzGZzq"
      },
      "source": [
        "y[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = GPU(np.random.randn(784,10))"
      ],
      "metadata": {
        "id": "G1MmJuRKC20Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: This line of code initializes a weight matrix `W` with random values using NumPy's `np.random.randn` function. The matrix has a shape of `(784, 10)`, which corresponds to 784 input features (assuming each image is flattened to a 1D array of length 784) and 10 output classes (assuming a multi-class classification task). The `GPU` function is then used to move this weight matrix to the GPU for processing with PyTorch."
      ],
      "metadata": {
        "id": "VrPrgULBG6aG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwMdXtr_4R0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNugjEScFiCC"
      },
      "source": [
        "x.shape, W.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fKhesUrFrYo"
      },
      "source": [
        "torch.matmul(x,W).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXUJJil7VyS_"
      },
      "source": [
        "(x@W).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: This code calculates the dot product between the input data `x` and the weight matrix `W` and returns the shape of the resulting matrix. The `@` operator is used for matrix multiplication. The shape of the resulting matrix will depend on the shape of `x` and `W`. If `x` has a shape of `(batch_size, 784)` and `W` has a shape of `(784, 10)`, the result will have a shape of `(batch_size, 10)`, where `batch_size` is the number of samples in the batch."
      ],
      "metadata": {
        "id": "CFu6JPbcHBza"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCUIYKR-Il3c"
      },
      "source": [
        "%%timeit\n",
        "x@W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: This code uses the `%%timeit` magic command in Jupyter or IPython to measure the execution time of the matrix multiplication operation `x@W`. It will run the operation multiple times and provide an average execution time. This can be useful for benchmarking the performance of different implementations or optimizations."
      ],
      "metadata": {
        "id": "esta6QgqHHDl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlQwtdaSeB5S"
      },
      "source": [
        "x@W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2hgdUkmeB8W"
      },
      "source": [
        "y2 = x@W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdZImnZFGeT6"
      },
      "source": [
        "plot(y2[:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQSssyK-GoB2"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "asy5jw0oy_F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(y):\n",
        "    y2 = GPU_data(torch.zeros((y.shape[0],10)))\n",
        "    for i in range(y.shape[0]):\n",
        "        y2[i,int(y[i])] = 1\n",
        "    return y2"
      ],
      "metadata": {
        "id": "BEgs4-skzhTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `one_hot` function takes an array `y` of labels and converts it into a one-hot encoded representation. It initializes a tensor `y2` filled with zeros, where each row corresponds to a label in `y`, and each column represents a class. It then iterates over each label in `y` and sets the corresponding element in `y2` to 1, effectively one-hot encoding the labels. This function is useful for converting class labels into a format suitable for certain machine learning algorithms."
      ],
      "metadata": {
        "id": "Tq3p3Lj49vF-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB2kNOUHGpIw"
      },
      "source": [
        "one_hot(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v91JZyTQeCMp"
      },
      "source": [
        "torch.argmax(y2,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hfl1lKrguTg"
      },
      "source": [
        "torch.sum(y == torch.argmax(y2,1))/b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz7Ea13HwarC"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNP2ahywwatJ"
      },
      "source": [
        "X@W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbGDRj7BwavA"
      },
      "source": [
        "torch.argmax(X@W,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXTb4Y4ywaw3"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_w3ksHVjQwu"
      },
      "source": [
        "torch.sum(torch.argmax(X@W,1) == Y)/60000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6RKfzVLnOTD"
      },
      "source": [
        "X@W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpOVv7nInOUw"
      },
      "source": [
        "W.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRq_ouBUnOWx"
      },
      "source": [
        "W[:,0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYWJulTHnOa1"
      },
      "source": [
        "plot(W[:,0].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tupFwuSZnOk9"
      },
      "source": [
        "plot(W[:,2].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvvy6MrAkC5Z"
      },
      "source": [
        "W.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCrJ9cNPkC76"
      },
      "source": [
        "(W.T).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAkEKB2_jQyy"
      },
      "source": [
        "montage_plot((W.T).reshape(10,28,28).cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4BlYG-CgC2z"
      },
      "source": [
        "def softmax(x):\n",
        "    s1 = torch.exp(x - torch.max(x,1)[0][:,None])\n",
        "    s = s1 / s1.sum(1)[:,None]\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `softmax` function takes a tensor `x` and computes the softmax activation for each row of the tensor, converting the raw scores into probabilities. It first subtracts the maximum value in each row from `x` to improve numerical stability, then exponentiates the result to get the numerator of the softmax function. It then normalizes the numerator by dividing by the sum of each row's elements to obtain the final probabilities."
      ],
      "metadata": {
        "id": "gO8DjVTOHjhZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ-UV8W_c_9o"
      },
      "source": [
        "def cross_entropy(outputs, labels):\n",
        "    return -torch.sum(softmax(outputs).log()[range(outputs.size()[0]), labels.long()])/outputs.size()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `cross_entropy` function computes the cross-entropy loss between the predicted `outputs` and the ground truth `labels`. It first computes the softmax activation of the `outputs` to convert them into probabilities, then calculates the negative logarithm of the predicted probability corresponding to the correct class label for each sample. The function sums these values across all samples and divides by the number of samples to compute the average loss per sample, which is returned as the final result."
      ],
      "metadata": {
        "id": "fseontI_HrCg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW3ttVcq1sI9"
      },
      "source": [
        "def acc(out,y):\n",
        "    return (torch.sum(torch.max(out,1)[1] == y).item())/y.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `acc` function calculates the accuracy of a model's predictions by comparing the predicted class labels (`torch.max(out, 1)[1]`) with the ground truth labels `y`. It sums the number of correct predictions, converts it to a Python number, and divides by the total number of samples (`y.shape[0]`) to compute the accuracy as a percentage."
      ],
      "metadata": {
        "id": "mNWqW22CH5C3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x79Sie8XKPOC"
      },
      "source": [
        "def get_batch(mode):\n",
        "    b = c.b\n",
        "    if mode == \"train\":\n",
        "        r = np.random.randint(X.shape[0]-b)\n",
        "        x = X[r:r+b,:]\n",
        "        y = Y[r:r+b]\n",
        "    elif mode == \"test\":\n",
        "        r = np.random.randint(X_test.shape[0]-b)\n",
        "        x = X_test[r:r+b,:]\n",
        "        y = Y_test[r:r+b]\n",
        "    return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `get_batch` function retrieves a batch of data (`x`) and corresponding labels (`y`) based on the specified `mode` (\"train\" or \"test\"). It obtains the batch size `b` from the variable `c.b`. When `mode` is \"train\", it selects a random batch of size `b` from the training data `X` and `Y`. When `mode` is \"test\", it selects a random batch of size `b` from the test data `X_test` and `Y_test`. The function then returns the batch `x` and labels `y`."
      ],
      "metadata": {
        "id": "_0H7gA00ICfk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXOr9aM8A8P-"
      },
      "source": [
        "def model(x,w):\n",
        "\n",
        "    return x@w[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment:The `model` function represents a simple linear model that computes the dot product between the input `x` and the first element of the weight matrix `w`. It returns the result of this dot product, which represents the output of the model. This function implements a basic linear transformation of the input `x` using the weights `w`."
      ],
      "metadata": {
        "id": "NupBt6H3IPm9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k6j0lacnYYk"
      },
      "source": [
        "def gradient_step(w):\n",
        "\n",
        "    w[0].data = w[0].data - c.L*w[0].grad.data\n",
        "\n",
        "    w[0].grad.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `gradient_step` function performs a single step of gradient descent on the weights `w` of a model. It updates the weights by subtracting a scaled version of their gradient (`c.L` times the gradient) to move them towards minimizing the loss function. After updating the weights, it zeros out the gradient to prepare for the next iteration. This function is used in the training process of machine learning models to iteratively improve their performance by adjusting the weights based on the gradient of the loss function."
      ],
      "metadata": {
        "id": "_Quk_45-Ijx0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzRsuDek9Fve"
      },
      "source": [
        "def make_plots():\n",
        "\n",
        "    acc_train = acc(model(x,w),y)\n",
        "\n",
        "    xt,yt = get_batch('test')\n",
        "\n",
        "    acc_test = acc(model(xt,w),yt)\n",
        "\n",
        "    wb.log({\"acc_train\": acc_train, \"acc_test\": acc_test})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `make_plots` function calculates the accuracy of the model on the training set (`acc_train`) and test set (`acc_test`) using the `acc` function. It then logs these accuracies using the `wb.log` function, which is typically used for tracking metrics during model training. This function is useful for monitoring the performance of the model on both training and test data over time."
      ],
      "metadata": {
        "id": "_MWxoP1QIwfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Truncated_Normal(size):\n",
        "\n",
        "    u1 = torch.rand(size)*(1-np.exp(-2)) + np.exp(-2)\n",
        "    u2 = torch.rand(size)\n",
        "    z  = torch.sqrt(-2*torch.log(u1)) * torch.cos(2*np.pi*u2)\n",
        "\n",
        "    return z"
      ],
      "metadata": {
        "id": "fx6a-FjX6bEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `Truncated_Normal` function generates samples from a truncated normal distribution using the acceptance-rejection method. It first generates random values `u1` from a uniform distribution between `np.exp(-2)` and `1`, and `u2` from a uniform distribution between 0 and 1. It then calculates `z` as a sample from a standard normal distribution, ensuring that values below -2 are truncated. The function returns the truncated normal samples `z`."
      ],
      "metadata": {
        "id": "S_39JKUqI7mE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_6a6qnKA7zP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ca15e82d-0e88-430c-f054-85e6d9742bd8"
      },
      "source": [
        "for run in range(3):\n",
        "\n",
        "    wb.init(project=\"Simple_Linear_SGD_123\");\n",
        "    c = wb.config\n",
        "\n",
        "    c.L = 0.1\n",
        "    c.b = 1024\n",
        "    c.epochs = 10000\n",
        "\n",
        "    w = [GPU(Truncated_Normal((784,10)))]\n",
        "\n",
        "    for i in range(c.epochs):\n",
        "\n",
        "        x,y = get_batch('train')\n",
        "\n",
        "        out = model(x,w)\n",
        "\n",
        "        loss = cross_entropy(softmax(out),y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        gradient_step(w)\n",
        "\n",
        "        make_plots()\n",
        "\n",
        "        if (i+1) % 10000 == 0: montage_plot((w[0].T).reshape(10,28,28).cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment:This code runs a training loop for a simple linear model using stochastic gradient descent (SGD) for optimization. It initializes Weights & Biases (wandb) for logging, sets up configurations such as learning rate, batch size, and number of epochs, and initializes the weight matrix. In each epoch, it retrieves a batch of training data, computes the model output and loss, performs backpropagation to update the weights, and logs the training and test accuracies. Optionally, it also plots a montage of the weights as images at every 10000th epoch for visualization."
      ],
      "metadata": {
        "id": "HPyXWkrhJAA_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WANJibeUNghZ"
      },
      "source": [
        "for run in range(100):\n",
        "\n",
        "    wb.init(project=\"Simple_Linear_Adam_2\");\n",
        "    c = wb.config\n",
        "\n",
        "    c.L = 0.01\n",
        "    c.b = 1024\n",
        "    c.epochs = 100000\n",
        "\n",
        "    w = [GPU(Truncated_Normal((784,10)))]\n",
        "\n",
        "    optimizer = torch.optim.Adam(w, lr=c.L)\n",
        "\n",
        "    for i in range(c.epochs):\n",
        "\n",
        "        x,y = get_batch('train')\n",
        "\n",
        "        loss = cross_entropy(softmax(model(x,w)),y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        wb.log({\"loss\": loss})\n",
        "\n",
        "        make_plots()\n",
        "\n",
        "        if i % 10000 == 0 : montage_plot((w[0].T).reshape(10,28,28).cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment:This code runs a training loop for a simple linear model using the Adam optimizer for optimization. It initializes Weights & Biases (wandb) for logging, sets up configurations such as learning rate, batch size, and number of epochs, and initializes the weight matrix. In each epoch, it retrieves a batch of training data, computes the model output and loss, performs a backward pass to calculate gradients, and updates the weights using the Adam optimizer. It logs the loss and optionally plots a montage of the weights as images at every 10000th epoch for visualization."
      ],
      "metadata": {
        "id": "aaPnCg3OJOqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Autoencoder\n"
      ],
      "metadata": {
        "id": "MMkIx6bTNy8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(mode):\n",
        "    b = 1024\n",
        "    if mode == \"train\":\n",
        "        r = np.random.randint(X.shape[0]-b)\n",
        "        x = X[r:r+b,:]\n",
        "        y = Y[r:r+b]\n",
        "    elif mode == \"test\":\n",
        "        r = np.random.randint(X_test.shape[0]-b)\n",
        "        x = X_test[r:r+b,:]\n",
        "        y = Y_test[r:r+b]\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "7QaW3xn0-M-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `get_batch` function retrieves a batch of data (`x`) and corresponding labels (`y`) based on the specified `mode` (\"train\" or \"test\") with a fixed batch size of 1024. When `mode` is \"train\", it selects a random batch of size 1024 from the training data `X` and `Y`. When `mode` is \"test\", it selects a random batch of size 1024 from the test data `X_test` and `Y_test`. The function then returns the batch `x` and labels `y`."
      ],
      "metadata": {
        "id": "gY8IUKM3JopF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.reshape(X.shape[0],1,28,28)\n",
        "X_test = X_test.reshape(X_test.shape[0],1,28,28)"
      ],
      "metadata": {
        "id": "WBQQOXS7XU-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torch.nn.functional import *"
      ],
      "metadata": {
        "id": "Ieh4jE_laYn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torchvision.transforms.functional.normalize(X,0.5,0.5)\n",
        "X_test = torchvision.transforms.functional.normalize(X_test,0.5,0.5)"
      ],
      "metadata": {
        "id": "N4StPT7VBG9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UafuXvzKjSw7"
      },
      "source": [
        "def Encoder(x,w):\n",
        "    x = relu(conv2d(x,w[0], stride=(2, 2), padding=(1, 1)))\n",
        "    x = relu(conv2d(x,w[1], stride=(2, 2), padding=(1, 1)))\n",
        "    x = x.view(x.size(0), 6272)\n",
        "    x = linear(x,w[2])\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `Encoder` function represents a neural network module used for encoding input data, likely in a convolutional autoencoder or a similar architecture. It applies two 2D convolutional layers with ReLU activation functions, reducing the spatial dimensions of the input and increasing the number of features. The output is then flattened and passed through a fully connected layer to further reduce the dimensionality, resulting in an encoded representation of the input."
      ],
      "metadata": {
        "id": "bJPv09LjJ5ND"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivvSdA3VjSw_"
      },
      "source": [
        "def Decoder(x,w):\n",
        "    x = linear(x,w[3])\n",
        "    x = x.view(x.size(0), 128, 7, 7)\n",
        "    x = relu(conv_transpose2d(x,w[4], stride=(2, 2), padding=(1, 1)))\n",
        "    x = torch.tanh(conv_transpose2d(x,w[5], stride=(2, 2), padding=(1, 1)))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `Decoder` function is a neural network module used for reconstructing encoded data. It applies a linear transformation to increase the dimensionality of the input, reshapes the tensor to prepare for transposed convolution operations, and then applies transposed convolution operations with ReLU and tanh activations to reconstruct the output. The final output represents the reconstructed data from the decoder."
      ],
      "metadata": {
        "id": "dSSFCOI5KKL2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8TLNLTkjSxG"
      },
      "source": [
        "def Autoencoder(x,w):\n",
        "    return Decoder(Encoder(x,w),w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `Autoencoder` function defines a complete autoencoder neural network, comprising an encoder and a decoder. It takes an input `x` and passes it through the encoder to produce an encoded representation. This encoded representation is then passed through the decoder to reconstruct the original input. The function returns the reconstructed output of the autoencoder for the input `x`, effectively training the autoencoder to learn a compressed representation of the input data."
      ],
      "metadata": {
        "id": "6-8mfRmmKgBE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iw6YTpBU8sr"
      },
      "source": [
        "num_steps = 1000\n",
        "batch_size = 512\n",
        "learning_rate = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "from imageio import *\n",
        "import torch\n",
        "from skimage.transform import resize\n",
        "from mpl_toolkits.axes_grid1.axes_rgb import make_rgb_axes, RGBAxes\n",
        "from torchvision.models import *\n",
        "from torchvision.datasets import MNIST,KMNIST,FashionMNIST\n",
        "from skimage.util import montage"
      ],
      "metadata": {
        "id": "wmj18jh0bJW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def randn_trunc(s): #Truncated Normal Random Numbers\n",
        "    mu = 0\n",
        "    sigma = 0.1\n",
        "    R = stats.truncnorm((-2*sigma - mu) / sigma, (2*sigma - mu) / sigma, loc=mu, scale=sigma)\n",
        "    return R.rvs(s)"
      ],
      "metadata": {
        "id": "3t3l54lzbGSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The `randn_trunc` function generates truncated normal random numbers with a mean of 0 and a standard deviation of 0.1. It uses the `scipy.stats.truncnorm` function to create a truncated normal distribution within the range [-0.2, 0.2]. The function then generates random numbers from this truncated normal distribution and returns them."
      ],
      "metadata": {
        "id": "inWypecrLel1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Au5YND2GU8sr"
      },
      "source": [
        "#Encode\n",
        "w0 = GPU(randn_trunc((64,1,4,4)))\n",
        "w1 = GPU(randn_trunc((128,64,4,4)))\n",
        "w2 = GPU(randn_trunc((10,6272)))\n",
        "#Decode\n",
        "w3 = GPU(randn_trunc((6272,10)))\n",
        "w4 = GPU(randn_trunc((128,64,4,4)))\n",
        "w5 = GPU(randn_trunc((64,1,4,4)))\n",
        "\n",
        "w = [w0,w1,w2,w3,w4,w5]\n",
        "\n",
        "optimizer = torch.optim.Adam(params=w, lr=learning_rate)\n",
        "\n",
        "for i in range(num_steps):\n",
        "\n",
        "    x_real,y = get_batch('train')\n",
        "\n",
        "    x_fake = Autoencoder(x_real,w)\n",
        "\n",
        "    loss = torch.mean((x_fake - x_real)**2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0: print(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: The code sets up an autoencoder model with encoder and decoder weights initialized using truncated normal random numbers. It then trains the autoencoder using the Adam optimizer to minimize the mean squared error between the reconstructed and real input data. The training loop iterates over a specified number of steps, where at each step, a batch of training data is used to update the weights. The loss is printed every 100 steps to monitor the training progress."
      ],
      "metadata": {
        "id": "Frc35S2gL4m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch,y = get_batch('test')"
      ],
      "metadata": {
        "id": "9KtDnM_cXeJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch_recon = Autoencoder(image_batch,w)"
      ],
      "metadata": {
        "id": "cUHiRtNJXeMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean((image_batch_recon - image_batch)**2)"
      ],
      "metadata": {
        "id": "kAvWP-HRXeYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "montage_plot(image_batch[0:25,0,:,:].cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "j9GNtjyxTrLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "montage_plot(image_batch_recon[0:25,0,:,:].cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "Mc87oPuJYFqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Generator\n",
        "\n"
      ],
      "metadata": {
        "id": "x4_p3zNkNz85"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OndxZEOPbAv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KqMhS0SbBZW"
      },
      "source": [
        "latent_size = 64\n",
        "hidden_size = 256\n",
        "image_size = 784\n",
        "b = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqUjdQl3bBZX"
      },
      "source": [
        "#MNIST\n",
        "# train_set = MNIST('./data', train=True, download=True)\n",
        "# test_set = MNIST('./data', train=False, download=True)\n",
        "\n",
        "#KMNIST\n",
        "#train_set = KMNIST('./data', train=True, download=True)\n",
        "#test_set = KMNIST('./data', train=False, download=True)\n",
        "\n",
        "#Fashion MNIST\n",
        "train_set = FashionMNIST('./data', train=True, download=True)\n",
        "test_set = FashionMNIST('./data', train=False, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAjtvOD9bBZX"
      },
      "source": [
        "X = train_set.data.numpy()\n",
        "X_test = test_set.data.numpy()\n",
        "Y = train_set.targets.numpy()\n",
        "Y_test = test_set.targets.numpy()\n",
        "X = X[:,None,:,:]/255\n",
        "X_test = X_test[:,None,:,:]/255\n",
        "X = (X - 0.5)/0.5\n",
        "X_test = (X_test - 0.5)/0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFT0i09GbBZX"
      },
      "source": [
        "n = 7\n",
        "\n",
        "index = np.where(Y == n)\n",
        "X = X[index]\n",
        "index = np.where(Y_test == n)\n",
        "X_test = X_test[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_6wZZTbBZX"
      },
      "source": [
        "X.shape,Y.shape,X_test.shape,Y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neg7qmgcbBZX"
      },
      "source": [
        "###################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfVSOFbebBZX"
      },
      "source": [
        "X = GPU_data(X)\n",
        "X_test = GPU_data(X_test)\n",
        "Y = GPU_data(Y)\n",
        "Y_test = GPU_data(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJfJfXm-bBZX"
      },
      "source": [
        "x,y = get_batch('train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTKyOsnC_GYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "Q197FoFQ-yM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V51COsfUbBZX"
      },
      "source": [
        "montage_plot(x[0:25,0,:,:].detach().cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7LYsL5_bBZX"
      },
      "source": [
        "#D\n",
        "w0 = GPU(randn_trunc((64,1,4,4)))\n",
        "w1 = GPU(randn_trunc((128,64,4,4)))\n",
        "w2 = GPU(randn_trunc((1,6272)))\n",
        "#G\n",
        "w3 = GPU(randn_trunc((6272,64)))\n",
        "w4 = GPU(randn_trunc((128,64,4,4)))\n",
        "w5 = GPU(randn_trunc((64,1,4,4)))\n",
        "\n",
        "w = [w0,w1,w2,w3,w4,w5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbDVggMGbBZX"
      },
      "source": [
        "def D(x,w):\n",
        "    x = relu(conv2d(x,w[0], stride=(2, 2), padding=(1, 1)))\n",
        "    x = relu(conv2d(x,w[1], stride=(2, 2), padding=(1, 1)))\n",
        "    x = x.view(x.size(0), 6272)\n",
        "    x = linear(x,w[2])\n",
        "    x = torch.sigmoid(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcOOwwfqbBZX"
      },
      "source": [
        "def G(x,w):\n",
        "    x = linear(x,w[3])\n",
        "    x = x.view(x.size(0), 128, 7, 7)\n",
        "    x = relu(conv_transpose2d(x,w[4], stride=(2, 2), padding=(1, 1)))\n",
        "    x = torch.tanh(conv_transpose2d(x,w[5], stride=(2, 2), padding=(1, 1)))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = 1024"
      ],
      "metadata": {
        "id": "nLHWIGrF-75j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = b"
      ],
      "metadata": {
        "id": "351S9-Hi-3dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size"
      ],
      "metadata": {
        "id": "iJoxfGJG-5CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md0XK_V0bBZX"
      },
      "source": [
        "d_optimizer = torch.optim.Adam(w[0:3], lr=0.0002)\n",
        "g_optimizer = torch.optim.Adam(w[3:], lr=0.0002)\n",
        "\n",
        "real_labels = (torch.ones(batch_size, 1).cuda())\n",
        "fake_labels = (torch.zeros(batch_size, 1).cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment:The code initializes two Adam optimizers, `d_optimizer` for the discriminator and `g_optimizer` for the generator, with a learning rate of 0.0002 each. It also creates tensors `real_labels` and `fake_labels` containing ones and zeros, respectively, used as labels for real and fake data in GAN training."
      ],
      "metadata": {
        "id": "AvKadTtSMM4a"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qIZIv7-bBZX"
      },
      "source": [
        "num_epochs = 500\n",
        "batches = X.shape[0]//batch_size\n",
        "steps = num_epochs*batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1da20dlbBZX"
      },
      "source": [
        "z1 = (torch.randn(steps,batch_size,latent_size).cuda())\n",
        "z2 = (torch.randn(steps,batch_size,latent_size).cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfr-JmZqbBZX"
      },
      "source": [
        "for i in range(steps):\n",
        "\n",
        "    images,y = get_batch('train')\n",
        "\n",
        "    d_loss = binary_cross_entropy(D(images,w), real_labels) + binary_cross_entropy(D(G(z1[i],w),w), fake_labels)\n",
        "    d_optimizer.zero_grad()\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "\n",
        "    g_loss = binary_cross_entropy(D(G(z2[i],w),w), real_labels)\n",
        "    g_optimizer.zero_grad()\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "\n",
        "    if i % 200 == 0:\n",
        "        out = G(z1[np.random.randint(steps)],w)\n",
        "        montage_plot(out.view(batch_size,1,28,28).detach().cpu().numpy()[0:25,0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment:This code snippet implements a training loop for a Generative Adversarial Network (GAN). It iterates over a specified number of steps, updating the discriminator and generator networks alternatively. The discriminator is trained to distinguish between real and fake images, while the generator is trained to generate images that are realistic enough to fool the discriminator. The discriminator loss is calculated as the sum of binary cross-entropy losses on real and fake images, while the generator loss is calculated using the binary cross-entropy loss on the discriminator's predictions on fake images. Every 200 steps, the code visualizes a set of generated images for monitoring the training progress."
      ],
      "metadata": {
        "id": "Yq7D6NGvMSVD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vws7NBXkPm8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJY1hGOIba67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z1[np.random.randint(steps)].shape"
      ],
      "metadata": {
        "id": "A_pN8FvYATEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = GPU_data(torch.randn(1,64))"
      ],
      "metadata": {
        "id": "tQAacm6dAVFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBPhGo-mbBZY"
      },
      "source": [
        "output = G(noise,w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "J-Ci-ogDAcn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(output[0,0])"
      ],
      "metadata": {
        "id": "XekLNuxzAieQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l9Km8G5vAlhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CXzsqpaLbAx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WDzaYAHGbAz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0oenv0v7bA2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXwRPV4ubA3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7fsqbWSobA6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PBBqbgVzbA8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Qs0nobTbA9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wy7yh74abBAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_0b021obBB_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}